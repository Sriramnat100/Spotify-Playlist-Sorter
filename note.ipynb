{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install spotipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Familiarizing Myself With The DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials, SpotifyOAuth\n",
    "import spotipy\n",
    "import sys\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import base64\n",
    "import json\n",
    "load_dotenv('.env')  \n",
    "\n",
    "CLIENT_ID = os.getenv('CLIENT_ID')\n",
    "CLIENT_SEC = os.getenv('CLIENT_SEC')\n",
    "\n",
    "\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(\n",
    "    client_id= CLIENT_ID,\n",
    "    client_secret= CLIENT_SEC,\n",
    "    redirect_uri=\"http://localhost:8888/callback\",\n",
    "    scope=\"user-library-read\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00dc1d3526eb40de814fd5cf63593524'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLIENT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kanye_uri=\"spotify:artist:5K4W6rqBFWDnAN6FQUkS6x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(sp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VULTURES 2\n",
      "VULTURES 1\n",
      "Donda (Deluxe)\n",
      "Donda\n",
      "JESUS IS KING\n",
      "KIDS SEE GHOSTS\n",
      "ye\n",
      "The Life Of Pablo\n",
      "Yeezus\n",
      "Watch The Throne (Deluxe)\n",
      "Watch The Throne\n",
      "My Beautiful Dark Twisted Fantasy\n",
      "808s & Heartbreak\n",
      "Graduation\n",
      "Late Registration\n",
      "The College Dropout\n"
     ]
    }
   ],
   "source": [
    "results = sp.artist_albums(kanye_uri, album_type='album')\n",
    "\n",
    "albums = results['items']\n",
    "ids = {}\n",
    "while results['next']:\n",
    "    results = sp.next(results)\n",
    "    albums.extend(results['items'])\n",
    "    \n",
    "for album in albums:\n",
    "    ids[album[\"name\"]] = album[\"id\"]\n",
    "    print(album['name'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vultures2 = sp.album_tracks(ids[\"VULTURES 2\"])\n",
    "vultures2 = vultures2[\"items\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: spotipy\n",
      "Version: 2.24.0\n",
      "Summary: A light weight Python library for the Spotify Web API\n",
      "Home-page: https://spotipy.readthedocs.org/\n",
      "Author: @plamere\n",
      "Author-email: paul@echonest.com\n",
      "License: MIT\n",
      "Location: /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages\n",
      "Requires: redis, requests, urllib3\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip3 show spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>available_markets</th>\n",
       "      <th>disc_number</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>external_urls</th>\n",
       "      <th>href</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>preview_url</th>\n",
       "      <th>track_number</th>\n",
       "      <th>type</th>\n",
       "      <th>uri</th>\n",
       "      <th>is_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>197777</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/5M...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/5MGMXOhVvwzC...</td>\n",
       "      <td>5MGMXOhVvwzCjFgdQsFokR</td>\n",
       "      <td>SLIDE</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:5MGMXOhVvwzCjFgdQsFokR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>159669</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/0J...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/0JgassGI6jNx...</td>\n",
       "      <td>0JgassGI6jNxpX82jGpcuJ</td>\n",
       "      <td>TIME MOVING SLOW</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:0JgassGI6jNxpX82jGpcuJ</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>163155</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/7v...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/7vv89PswQvqG...</td>\n",
       "      <td>7vv89PswQvqGKCGJ1rw5on</td>\n",
       "      <td>FIELD TRIP</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:7vv89PswQvqGKCGJ1rw5on</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>166400</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/4Q...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/4Qay2jEWJYjX...</td>\n",
       "      <td>4Qay2jEWJYjXmJ8eNOGtaD</td>\n",
       "      <td>FRIED</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:4Qay2jEWJYjXmJ8eNOGtaD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>8895</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/36...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/36XrocrUkmem...</td>\n",
       "      <td>36XrocrUkmem00MPm2kIst</td>\n",
       "      <td>ISABELLA</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:36XrocrUkmem00MPm2kIst</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>158980</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/6b...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/6bSfeCXlUaGa...</td>\n",
       "      <td>6bSfeCXlUaGa3eWCy5qPTb</td>\n",
       "      <td>PROMOTION</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:6bSfeCXlUaGa3eWCy5qPTb</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>288000</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/2t...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/2tPNj9sUt3Fb...</td>\n",
       "      <td>2tPNj9sUt3FbjEUqBzZazv</td>\n",
       "      <td>530</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:2tPNj9sUt3FbjEUqBzZazv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>263283</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/48...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/488lIy4J0jJd...</td>\n",
       "      <td>488lIy4J0jJdPUiWqa0doB</td>\n",
       "      <td>DEAD</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:488lIy4J0jJdPUiWqa0doB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>194655</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/1M...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/1MTpRBLniy62...</td>\n",
       "      <td>1MTpRBLniy6298BCdyKUfQ</td>\n",
       "      <td>FOREVER ROLLING</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:1MTpRBLniy6298BCdyKUfQ</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>151263</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/2k...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/2kgxyflhiicD...</td>\n",
       "      <td>2kgxyflhiicDbF8SDrBxqy</td>\n",
       "      <td>BOMB</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:2kgxyflhiicDbF8SDrBxqy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>214545</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/5R...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/5RzSnxqTx4vY...</td>\n",
       "      <td>5RzSnxqTx4vYEp9re5E0ud</td>\n",
       "      <td>RIVER</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:5RzSnxqTx4vYEp9re5E0ud</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>135737</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/1C...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/1Cxq3u0RQ0tE...</td>\n",
       "      <td>1Cxq3u0RQ0tEBbVofZ9Mma</td>\n",
       "      <td>FOREVER</td>\n",
       "      <td>None</td>\n",
       "      <td>12</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:1Cxq3u0RQ0tEBbVofZ9Mma</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>137600</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/6L...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/6LHeisjoP8eH...</td>\n",
       "      <td>6LHeisjoP8eHrtu45UbTPO</td>\n",
       "      <td>HUSBAND</td>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:6LHeisjoP8eHrtu45UbTPO</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>203200</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/40...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/40FRxwg8SEMO...</td>\n",
       "      <td>40FRxwg8SEMO3fbMjFfphU</td>\n",
       "      <td>LIFESTYLE</td>\n",
       "      <td>None</td>\n",
       "      <td>14</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:40FRxwg8SEMO3fbMjFfphU</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>262025</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/7a...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/7a0tTD7xdvKs...</td>\n",
       "      <td>7a0tTD7xdvKsNcJfMIDWp4</td>\n",
       "      <td>SKY CITY</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:7a0tTD7xdvKsNcJfMIDWp4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>[AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...</td>\n",
       "      <td>1</td>\n",
       "      <td>237361</td>\n",
       "      <td>True</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/3b...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/3bTkWuPGJ1ue...</td>\n",
       "      <td>3bTkWuPGJ1ueGXBHWVUwAI</td>\n",
       "      <td>MY SOUL</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:3bTkWuPGJ1ueGXBHWVUwAI</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              artists  \\\n",
       "0   [{'external_urls': {'spotify': 'https://open.s...   \n",
       "1   [{'external_urls': {'spotify': 'https://open.s...   \n",
       "2   [{'external_urls': {'spotify': 'https://open.s...   \n",
       "3   [{'external_urls': {'spotify': 'https://open.s...   \n",
       "4   [{'external_urls': {'spotify': 'https://open.s...   \n",
       "5   [{'external_urls': {'spotify': 'https://open.s...   \n",
       "6   [{'external_urls': {'spotify': 'https://open.s...   \n",
       "7   [{'external_urls': {'spotify': 'https://open.s...   \n",
       "8   [{'external_urls': {'spotify': 'https://open.s...   \n",
       "9   [{'external_urls': {'spotify': 'https://open.s...   \n",
       "10  [{'external_urls': {'spotify': 'https://open.s...   \n",
       "11  [{'external_urls': {'spotify': 'https://open.s...   \n",
       "12  [{'external_urls': {'spotify': 'https://open.s...   \n",
       "13  [{'external_urls': {'spotify': 'https://open.s...   \n",
       "14  [{'external_urls': {'spotify': 'https://open.s...   \n",
       "15  [{'external_urls': {'spotify': 'https://open.s...   \n",
       "\n",
       "                                    available_markets  disc_number  \\\n",
       "0   [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "1   [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "2   [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "3   [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "4   [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "5   [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "6   [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "7   [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "8   [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "9   [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "10  [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "11  [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "12  [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "13  [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "14  [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "15  [AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, C...            1   \n",
       "\n",
       "    duration_ms  explicit                                      external_urls  \\\n",
       "0        197777      True  {'spotify': 'https://open.spotify.com/track/5M...   \n",
       "1        159669      True  {'spotify': 'https://open.spotify.com/track/0J...   \n",
       "2        163155      True  {'spotify': 'https://open.spotify.com/track/7v...   \n",
       "3        166400      True  {'spotify': 'https://open.spotify.com/track/4Q...   \n",
       "4          8895      True  {'spotify': 'https://open.spotify.com/track/36...   \n",
       "5        158980      True  {'spotify': 'https://open.spotify.com/track/6b...   \n",
       "6        288000      True  {'spotify': 'https://open.spotify.com/track/2t...   \n",
       "7        263283      True  {'spotify': 'https://open.spotify.com/track/48...   \n",
       "8        194655      True  {'spotify': 'https://open.spotify.com/track/1M...   \n",
       "9        151263      True  {'spotify': 'https://open.spotify.com/track/2k...   \n",
       "10       214545      True  {'spotify': 'https://open.spotify.com/track/5R...   \n",
       "11       135737      True  {'spotify': 'https://open.spotify.com/track/1C...   \n",
       "12       137600      True  {'spotify': 'https://open.spotify.com/track/6L...   \n",
       "13       203200      True  {'spotify': 'https://open.spotify.com/track/40...   \n",
       "14       262025      True  {'spotify': 'https://open.spotify.com/track/7a...   \n",
       "15       237361      True  {'spotify': 'https://open.spotify.com/track/3b...   \n",
       "\n",
       "                                                 href                      id  \\\n",
       "0   https://api.spotify.com/v1/tracks/5MGMXOhVvwzC...  5MGMXOhVvwzCjFgdQsFokR   \n",
       "1   https://api.spotify.com/v1/tracks/0JgassGI6jNx...  0JgassGI6jNxpX82jGpcuJ   \n",
       "2   https://api.spotify.com/v1/tracks/7vv89PswQvqG...  7vv89PswQvqGKCGJ1rw5on   \n",
       "3   https://api.spotify.com/v1/tracks/4Qay2jEWJYjX...  4Qay2jEWJYjXmJ8eNOGtaD   \n",
       "4   https://api.spotify.com/v1/tracks/36XrocrUkmem...  36XrocrUkmem00MPm2kIst   \n",
       "5   https://api.spotify.com/v1/tracks/6bSfeCXlUaGa...  6bSfeCXlUaGa3eWCy5qPTb   \n",
       "6   https://api.spotify.com/v1/tracks/2tPNj9sUt3Fb...  2tPNj9sUt3FbjEUqBzZazv   \n",
       "7   https://api.spotify.com/v1/tracks/488lIy4J0jJd...  488lIy4J0jJdPUiWqa0doB   \n",
       "8   https://api.spotify.com/v1/tracks/1MTpRBLniy62...  1MTpRBLniy6298BCdyKUfQ   \n",
       "9   https://api.spotify.com/v1/tracks/2kgxyflhiicD...  2kgxyflhiicDbF8SDrBxqy   \n",
       "10  https://api.spotify.com/v1/tracks/5RzSnxqTx4vY...  5RzSnxqTx4vYEp9re5E0ud   \n",
       "11  https://api.spotify.com/v1/tracks/1Cxq3u0RQ0tE...  1Cxq3u0RQ0tEBbVofZ9Mma   \n",
       "12  https://api.spotify.com/v1/tracks/6LHeisjoP8eH...  6LHeisjoP8eHrtu45UbTPO   \n",
       "13  https://api.spotify.com/v1/tracks/40FRxwg8SEMO...  40FRxwg8SEMO3fbMjFfphU   \n",
       "14  https://api.spotify.com/v1/tracks/7a0tTD7xdvKs...  7a0tTD7xdvKsNcJfMIDWp4   \n",
       "15  https://api.spotify.com/v1/tracks/3bTkWuPGJ1ue...  3bTkWuPGJ1ueGXBHWVUwAI   \n",
       "\n",
       "                name preview_url  track_number   type  \\\n",
       "0              SLIDE        None             1  track   \n",
       "1   TIME MOVING SLOW        None             2  track   \n",
       "2         FIELD TRIP        None             3  track   \n",
       "3              FRIED        None             4  track   \n",
       "4           ISABELLA        None             5  track   \n",
       "5          PROMOTION        None             6  track   \n",
       "6                530        None             7  track   \n",
       "7               DEAD        None             8  track   \n",
       "8    FOREVER ROLLING        None             9  track   \n",
       "9               BOMB        None            10  track   \n",
       "10             RIVER        None            11  track   \n",
       "11           FOREVER        None            12  track   \n",
       "12           HUSBAND        None            13  track   \n",
       "13         LIFESTYLE        None            14  track   \n",
       "14          SKY CITY        None            15  track   \n",
       "15           MY SOUL        None            16  track   \n",
       "\n",
       "                                     uri  is_local  \n",
       "0   spotify:track:5MGMXOhVvwzCjFgdQsFokR     False  \n",
       "1   spotify:track:0JgassGI6jNxpX82jGpcuJ     False  \n",
       "2   spotify:track:7vv89PswQvqGKCGJ1rw5on     False  \n",
       "3   spotify:track:4Qay2jEWJYjXmJ8eNOGtaD     False  \n",
       "4   spotify:track:36XrocrUkmem00MPm2kIst     False  \n",
       "5   spotify:track:6bSfeCXlUaGa3eWCy5qPTb     False  \n",
       "6   spotify:track:2tPNj9sUt3FbjEUqBzZazv     False  \n",
       "7   spotify:track:488lIy4J0jJdPUiWqa0doB     False  \n",
       "8   spotify:track:1MTpRBLniy6298BCdyKUfQ     False  \n",
       "9   spotify:track:2kgxyflhiicDbF8SDrBxqy     False  \n",
       "10  spotify:track:5RzSnxqTx4vYEp9re5E0ud     False  \n",
       "11  spotify:track:1Cxq3u0RQ0tEBbVofZ9Mma     False  \n",
       "12  spotify:track:6LHeisjoP8eHrtu45UbTPO     False  \n",
       "13  spotify:track:40FRxwg8SEMO3fbMjFfphU     False  \n",
       "14  spotify:track:7a0tTD7xdvKsNcJfMIDWp4     False  \n",
       "15  spotify:track:3bTkWuPGJ1ueGXBHWVUwAI     False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(vultures2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5MGMXOhVvwzCjFgdQsFokR', '0JgassGI6jNxpX82jGpcuJ']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [\"5MGMXOhVvwzCjFgdQsFokR\", \"0JgassGI6jNxpX82jGpcuJ\"]\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spotify:track:5MGMXOhVvwzCjFgdQsFokR'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"uri\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTracks(albumName):\n",
    "    try:\n",
    "        albumData = sp.album_tracks(ids[albumName])\n",
    "    except:\n",
    "        return \"Album Not Found\"\n",
    "\n",
    "    tempDf = pd.DataFrame(albumData[\"items\"])\n",
    "\n",
    "    \n",
    "    return tempDf.set_index('id')['name'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'6MXXY2eiWkpDCezVCc0cMH': 'Good Morning',\n",
       " '4UQMOPSUVJVicIQzjAcRRZ': 'Champion',\n",
       " '0j2T0R9dR9qdJYsB7ciXhf': 'Stronger',\n",
       " '7rbECVPkY5UODxoOUVKZnA': 'I Wonder',\n",
       " '4ZPdLEztrlZqbJkgHNw54L': 'Good Life',\n",
       " '0mEdbdeRFQwBhN4xfyIeUM': \"Can't Tell Me Nothing\",\n",
       " '7387VaiHpOsSIZ5nmjseya': 'Barry Bonds',\n",
       " '7DRuzSlhjKadgdsQRYZ0tr': 'Drunk and Hot Girls',\n",
       " '5TRPicyLGbAF2LGBFbHGvO': 'Flashing Lights',\n",
       " '0NrtwAmRAdLxua31SzHvXr': 'Everything I Am',\n",
       " '0lWjRSzq5chA9fps3pM8Zr': 'The Glory',\n",
       " '4iz9lGMjU1lXS51oPmUmTe': 'Homecoming',\n",
       " '2L47m9erkB5KBZcaqWtYen': 'Big Brother',\n",
       " '3bhyo2ED5Yd4RLydQBDtD6': 'Good Night'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTracks(\"Graduation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spotify:track:5MGMXOhVvwzCjFgdQsFokR'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"uri\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.audio_analysis(df[\"uri\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8477.80s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lyrics_extractor\n",
      "  Downloading lyrics_extractor-3.0.1-py3-none-any.whl (7.1 kB)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from lyrics_extractor) (2.31.0)\n",
      "Collecting lxml\n",
      "  Downloading lxml-5.3.0-cp310-cp310-macosx_10_9_universal2.whl (8.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from lyrics_extractor) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from beautifulsoup4->lyrics_extractor) (2.3.2.post1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->lyrics_extractor) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->lyrics_extractor) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->lyrics_extractor) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->lyrics_extractor) (3.1.0)\n",
      "Installing collected packages: lxml, lyrics_extractor\n",
      "Successfully installed lxml-5.3.0 lyrics_extractor-3.0.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.10/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install lyrics_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lyrics_extractor import SongLyrics \n",
    "# extract_lyrics = SongLyrics(\"AIzaSyDIs8aSDwfud5MR4FuNou5gmet_VTkLgm4\", \"74f6756411b824d00\")\n",
    "# extract_lyrics.get_lyrics(\"Tujhse Naraz Nahi Zindagi Lyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"lyrics\":\"Yeah\\\\r\\\\nWheezy out of here\\\\r\\\\nThe dash, it\\'s digi\\', the schedule busy\\\\r\\\\nMy head in a hoodie, my shorty a goodie\\\\r\\\\nMy cousins are crazy, my cousins like Boogie\\\\n\\\\nLife is amazin\\', it is what it should be\\\\n\\\\nBeen here for ten but I feel like a rookie\\\\n\\\\nI tell her, \\\\\"look up\\\\\" \\'cause it\\'s snowin\\' in Tootsie\\'s\\\\n\\\\nBooked for three years, man you can\\'t even book me\\\\n\\\\nIt\\'s me and Lil Baby, this shit goin\\' crazy\\\\n\\\\nWheezy produced it and Weezy F. made me\\\\n\\\\nAnd she held it down, so she got a Mercedes\\\\n\\\\nYoung Money Records, the Army, the Navy\\\\n\\\\nThey ran me ten thousand, I threw it like Brady\\\\n\\\\nThe foreign is yellow like Tracee and K.D\\\\n\\\\nI trusted my niggas, they never betrayed me\\\\n\\\\nMet all these niggas, they sweeter than Sadie\\\\n\\\\nWhen I started out, I just took what they gave me\\\\n\\\\nDid all the favors, they never repaid me\\\\n\\\\nIt worked in my favor, \\'cause nobody saved me\\\\n\\\\n\\\\n\\\\nBrand new whip got no keys\\\\n\\\\nTailor my clothes, no starch please\\\\n\\\\nSoon as I nut, you can gon\\' leave\\\\n\\\\nGot M\\'s in the bank, like \\\\\"yes, indeed\\\\\"\\\\n\\\\n\\\\n\\\\nCartier glasses, I won\\'t even peek at you\\\\n\\\\nYellow Ferrari like Pikachu\\\\n\\\\nI got \\'em waitin\\' and watchin\\' what he gon\\' do\\\\n\\\\nTryna peep what I do, tryna steal my moves\\\\n\\\\n$2,500 for a new pair of tennis shoes\\\\n\\\\nThe same price, I could make them youngins come and finish you\\\\n\\\\nLawyer been chargin\\', he a Jewish like he voodoo\\\\n\\\\nReal dope boy, hundred thousand in Evisu\\\\n\\\\nPresidential tints slide by, we don\\'t see you\\\\n\\\\nI been gettin\\' money, I ain\\'t worried \\'bout what he do\\\\n\\\\nI\\'m gettin\\' money like I\\'m from the \\'80s\\\\n\\\\nMe and Drake \\'bout to drop man, this shit gon\\' go crazy\\\\n\\\\nThey know I\\'m the truth, comin\\' straight from the basement\\\\n\\\\nI\\'m straight as the street, man I come from the pavement\\\\n\\\\nA million, all hundreds, it make em \\'go crazy\\\\n\\\\nWah-wah-wah, bitch I\\'m Lil Baby\\\\n\\\\n\\\\n\\\\nBrand new whip got no keys\\\\n\\\\nTailor my clothes, no starch please\\\\n\\\\nSoon as I nut, you can gon\\' leave\\\\n\\\\nGot M\\'s in the bank, like yes indeed\\\\n\\\\nMe and my dawgs goin\\' all the way\\\\n\\\\nWhen you livin\\' like this, they supposed to hate\\\\n\\\\nBrand new whip got no keys\\\\n\\\\nTailor my clothes, no starch please\\\\n\\\\nSoon as I nut, you can gon\\' leave\\\\n\\\\nGot M\\'s in the bank, like yes indeed\\\\n\\\\nMe and my dawgs going all the way\\\\n\\\\nWhen you livin\\' like this, they supposed to hate\"}'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "\n",
    "with urllib.request.urlopen('https://api.lyrics.ovh/v1/Lil+Baby/Yes+Indeed') as response:\n",
    "    html = str(response.read())\n",
    "\n",
    "print(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatSong(songName):\n",
    "    songName = songName.split()\n",
    "    s = songName[0]\n",
    "    if (len(songName) != 1):\n",
    "        for i in range(1,len(songName)):\n",
    "            s =  s + \"+\" + songName[i]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def getSong(artistName, songName):\n",
    "\n",
    "    artistName = formatSong(artistName)\n",
    "    songName = formatSong(songName)\n",
    "    \n",
    "    url = 'https://api.lyrics.ovh/v1/' + artistName + '/' + songName + ''\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        html = str(response.read())\n",
    "    \n",
    "    \n",
    "    #Cleaning up the lyrics\n",
    "    listLyrics = html.split(\"lyrics\", 1)\n",
    "    listLyrics = listLyrics[1].replace(\"\\\\n\", \", \")\n",
    "    listLyrics = listLyrics.replace(\"\\\\r\", \"\")\n",
    "    listLyrics = listLyrics.replace(\"\\\\\", \"\")\n",
    "    pattern = r'\\[.*?\\]'\n",
    "    clean_text = re.sub(pattern, '', listLyrics)\n",
    "    pattern_parentheses = r'\\(.*?\\)'\n",
    "    pattern_commas = r',\\s*,+'\n",
    "    clean_text = re.sub(pattern_parentheses, '', clean_text)\n",
    "    clean_text = re.sub(pattern_commas, '', clean_text)\n",
    "\n",
    "    \n",
    "    return clean_text\n",
    "    # return listLyrics\n",
    "\n",
    "song = getSong(\"Kanye West\", \"Good Life\")\n",
    "print(type(song))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Detection\n",
    "\n",
    "First, I will be using nrclex. Next, I will try out hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9577.21s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nrclex in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.0.0)\n",
      "Requirement already satisfied: textblob in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nrclex) (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textblob->nrclex) (3.8.1)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk>=3.8->textblob->nrclex) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk>=3.8->textblob->nrclex) (2023.5.5)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk>=3.8->textblob->nrclex) (4.65.0)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk>=3.8->textblob->nrclex) (8.1.3)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.10/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install nrclex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nrclex import NRCLex \n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = NRCLex(getSong(\"Drake\", \"Over my dead body\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How', 'I', \"'m\", 'feeling', 'it', 'does', \"n't\", 'matter', 'Cause', 'you', 'know', 'I', \"'m\", 'okay', 'Instead', 'I', 'ask', 'myself', 'why', 'do', 'you', 'hurt', 'me', 'When', 'you', 'know', 'you', 'know', 'I', \"'m\", 'the', 'same', 'I', 'know', 'I', 'know', 'that', 'you', 'love', 'me', 'baby', 'Time', 'to', 'take', 'you', 'away', 'from', 'me', 'Only', 'over', 'my', 'dead', 'body', 'I', 'think', 'I', 'killed', 'everybody', 'in', 'the', 'game', 'last', 'year', 'man', 'Fuck', 'it', 'I', 'was', 'on', 'though', 'And', 'I', 'thought', 'I', 'found', 'the', 'girl', 'of', 'my', 'dreams', 'at', 'a', 'strip', 'club', 'Fuck', 'it', 'I', 'was', 'wrong', 'though', 'Shout', 'out', 'all', 'to', 'all', 'my', 'niggas', 'living', 'tax', 'free', 'Now-a-days', 'it', \"'s\", 'six', 'figures', 'when', 'they', 'tax', 'me', 'Oh', 'well', 'I', 'guess', 'you', 'lose', 'some', 'and', 'win', 'some', 'Long', 'as', 'the', 'outcome', 'is', 'income', 'You', 'know', 'I', 'want', 'it', 'all', 'and', 'then', 'some', 'Shout', 'out', 'to', 'Asian', 'girls', 'let', 'the', 'lights', 'dim', 'sum', 'Shots', 'came', 'I', 'do', \"n't\", 'know', 'where', 'they', 'was', 'sent', 'from', 'Probably', 'some', 'bad', 'hoes', 'about', 'to', 'take', 'the', 'hemp', 'from', 'Yeah', 'you', 'know', 'me', 'well', 'nigga', 'I', 'mean', 'you', 'ai', \"n't\", 'the', 'only', 'real', 'nigga', 'They', 'got', 'me', 'on', 'these', 'white', 'women', 'like', 'Seal', 'nigga', 'Slave', 'to', 'the', 'pussy', 'but', 'I', \"'m\", 'just', 'playing', 'the', 'field', 'nigga', 'Are', 'these', 'people', 'discussing', 'my', 'career', 'again', 'Asking', 'if', 'I', \"'ll\", 'be', 'going', 'platinum', 'in', 'a', 'year', 'again', 'Do', \"n't\", 'I', 'got', 'the', 'shit', 'the', 'world', 'wan', 'na', 'hear', 'again', 'Do', \"n't\", 'Michael', 'Jordan', 'still', 'got', 'his', 'hoop', 'earing', 'in', 'Man', 'all', 'of', 'your', 'flows', 'bore', 'me', 'paint', 'drying', 'And', 'I', 'do', \"n't\", 'ever', 'be', 'trippin', 'off', 'of', 'what', 'ai', \"n't\", 'mine', 'And', 'I', 'be', 'hearing', 'shit', 'you', 'say', 'through', 'the', 'grapevine', 'But', 'jealousy', 'is', 'just', 'love', 'and', 'hate', 'at', 'the', 'same', 'time', 'It', \"'s\", 'been', 'that', 'way', 'from', 'the', 'beginning', 'I', 'just', 'been', 'playing', 'I', 'ai', \"n't\", 'even', 'know', 'that', 'I', 'was', 'winning', 'And', 'this', 'is', 'the', 'only', 'sound', 'you', 'should', 'fear', 'Man', 'these', 'kids', 'wear', 'crowns', 'over', 'here', 'and', 'everything', 'is', 'alright', 'I', 'know', 'I', 'know', 'that', 'you', 'love', 'me', 'baby', 'The', 'time', 'to', 'take', 'you', 'away', 'from', 'me', 'Only', 'over', 'my', 'dead', 'body', 'You', 'say', 'I', \"'m\", 'old', 'news', 'where', 'who', 'the', 'new', 'star', 'Cause', 'if', 'I', \"'m\", 'going', 'anyway', 'it', \"'s\", 'probably', 'too', 'far', 'Just', 'performed', 'at', 'a', 'Bar', 'Mitzvah', 'over', 'in', 'the', 'states', 'Used', 'half', 'of', 'the', 'money', 'to', 'beat', 'my', 'brother', \"'s\", 'case', 'Red', 'wine', 'over', 'Fed', 'time', 'And', 'shout', 'out', 'to', 'the', 'niggas', 'that', \"'s\", 'doing', 'deadtime', 'Shout', 'out', 'to', 'the', 'bitches', 'there', 'when', 'it', \"'s\", 'bedtime', 'And', 'fuck', 'you', 'to', 'the', 'niggas', 'that', 'think', 'it', \"'s\", 'their', 'time', 'Yeah', 'do', \"n't\", 'make', 'me', 'take', 'your', 'life', 'apart', 'boy', 'You', 'and', 'whoever', 'the', 'fuck', 'gave', 'you', 'your', 'start', 'boy', 'Or', 'you', 'wan', 'na', 'be', 'a', 'muthafuckin', 'funny', 'guy', 'Do', \"n't\", 'make', 'me', 'break', 'your', 'Kevin', 'heart', 'boy', 'Yeah', 'it', \"'s\", 'whatever', 'You', 'know', 'feeling', 'good', 'living', 'better', 'I', 'think', 'maybe', 'I', 'was', 'numb', 'to', 'it', 'last', 'year', 'But', 'you', 'know', 'I', 'feel', 'it', 'now', 'more', 'than', 'ever', 'My', 'city', 'love', 'me', 'like', 'Mac', 'Dre', 'in', 'the', 'Bay', 'Second', 'album', 'I', \"'m\", 'back', 'paving', 'the', 'way', 'The', 'backpackers', 'are', 'back', 'on', 'the', 'bandwagon', 'Like', 'this', 'was', 'my', 'comeback', 'season', 'back', 'back', 'in', 'the', 'day', 'And', 'I', 'met', 'your', 'baby', 'moms', 'last', 'night', 'We', 'took', 'a', 'picture', 'together', 'I', 'hope', 'she', 'frames', 'it', 'And', 'I', 'was', 'drinking', 'at', 'the', 'Palms', 'last', 'night', 'And', 'ended', 'up', 'losing', 'everything', 'that', 'I', 'came', 'with', 'Feel', 'like', 'I', \"'ve\", 'been', 'here', 'before', 'huh', 'I', 'still', 'got', '10', 'years', 'to', 'go', 'huh', 'This', 'is', 'the', 'only', 'sound', 'you', 'should', 'fear', 'These', 'kids', 'wear', 'crowns', 'over', 'here', 'And', 'everything', 'is', 'all', 'right', 'I', 'know', 'I', 'know', 'that', 'you', 'love', 'me', 'baby', 'The', 'time', 'to', 'take', 'you', 'away', 'from', 'me', 'Only', 'over', 'my', 'dead', 'body']\n"
     ]
    }
   ],
   "source": [
    "print(emotion.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('negative', 0.17365269461077845)]\n"
     ]
    }
   ],
   "source": [
    "print(emotion.top_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ['How', 'I', \"'m\", 'feeling', 'it', 'does', \"n't\", 'matter', 'Cause', 'you', 'know', 'I', \"'m\", 'okay', 'Instead', 'I', 'ask', 'myself', 'why', 'do', 'you', 'hurt', 'me', 'When', 'you', 'know', 'you', 'know', 'I', \"'m\", 'the', 'same', 'I', 'know', 'I', 'know', 'that', 'you', 'love', 'me', 'baby', 'Time', 'to', 'take', 'you', 'away', 'from', 'me', 'Only', 'over', 'my', 'dead', 'body', 'I', 'think', 'I', 'killed', 'everybody', 'in', 'the', 'game', 'last', 'year', 'man', 'Fuck', 'it', 'I', 'was', 'on', 'though', 'And', 'I', 'thought', 'I', 'found', 'the', 'girl', 'of', 'my', 'dreams', 'at', 'a', 'strip', 'club', 'Fuck', 'it', 'I', 'was', 'wrong', 'though', 'Shout', 'out', 'all', 'to', 'all', 'my', 'niggas', 'living', 'tax', 'free', 'Now-a-days', 'it', \"'s\", 'six', 'figures', 'when', 'they', 'tax', 'me', 'Oh', 'well', 'I', 'guess', 'you', 'lose', 'some', 'and', 'win', 'some', 'Long', 'as', 'the', 'outcome', 'is', 'income', 'You', 'know', 'I', 'want', 'it', 'all', 'and', 'then', 'some', 'Shout', 'out', 'to', 'Asian', 'girls', 'let', 'the', 'lights', 'dim', 'sum', 'Shots', 'came', 'I', 'do', \"n't\", 'know', 'where', 'they', 'was', 'sent', 'from', 'Probably', 'some', 'bad', 'hoes', 'about', 'to', 'take', 'the', 'hemp', 'from', 'Yeah', 'you', 'know', 'me', 'well', 'nigga', 'I', 'mean', 'you', 'ai', \"n't\", 'the', 'only', 'real', 'nigga', 'They', 'got', 'me', 'on', 'these', 'white', 'women', 'like', 'Seal', 'nigga', 'Slave', 'to', 'the', 'pussy', 'but', 'I', \"'m\", 'just', 'playing', 'the', 'field', 'nigga', 'Are', 'these', 'people', 'discussing', 'my', 'career', 'again', 'Asking', 'if', 'I', \"'ll\", 'be', 'going', 'platinum', 'in', 'a', 'year', 'again', 'Do', \"n't\", 'I', 'got', 'the', 'shit', 'the', 'world', 'wan', 'na', 'hear', 'again', 'Do', \"n't\", 'Michael', 'Jordan', 'still', 'got', 'his', 'hoop', 'earing', 'in', 'Man', 'all', 'of', 'your', 'flows', 'bore', 'me', 'paint', 'drying', 'And', 'I', 'do', \"n't\", 'ever', 'be', 'trippin', 'off', 'of', 'what', 'ai', \"n't\", 'mine', 'And', 'I', 'be', 'hearing', 'shit', 'you', 'say', 'through', 'the', 'grapevine', 'But', 'jealousy', 'is', 'just', 'love', 'and', 'hate', 'at', 'the', 'same', 'time', 'It', \"'s\", 'been', 'that', 'way', 'from', 'the', 'beginning', 'I', 'just', 'been', 'playing', 'I', 'ai', \"n't\", 'even', 'know', 'that', 'I', 'was', 'winning', 'And', 'this', 'is', 'the', 'only', 'sound', 'you', 'should', 'fear', 'Man', 'these', 'kids', 'wear', 'crowns', 'over', 'here', 'and', 'everything', 'is', 'alright', 'I', 'know', 'I', 'know', 'that', 'you', 'love', 'me', 'baby', 'The', 'time', 'to', 'take', 'you', 'away', 'from', 'me', 'Only', 'over', 'my', 'dead', 'body', 'You', 'say', 'I', \"'m\", 'old', 'news', 'where', 'who', 'the', 'new', 'star', 'Cause', 'if', 'I', \"'m\", 'going', 'anyway', 'it', \"'s\", 'probably', 'too', 'far', 'Just', 'performed', 'at', 'a', 'Bar', 'Mitzvah', 'over', 'in', 'the', 'states', 'Used', 'half', 'of', 'the', 'money', 'to', 'beat', 'my', 'brother', \"'s\", 'case', 'Red', 'wine', 'over', 'Fed', 'time', 'And', 'shout', 'out', 'to', 'the', 'niggas', 'that', \"'s\", 'doing', 'deadtime', 'Shout', 'out', 'to', 'the', 'bitches', 'there', 'when', 'it', \"'s\", 'bedtime', 'And', 'fuck', 'you', 'to', 'the', 'niggas', 'that', 'think', 'it', \"'s\", 'their', 'time', 'Yeah', 'do', \"n't\", 'make', 'me', 'take', 'your', 'life', 'apart', 'boy', 'You', 'and', 'whoever', 'the', 'fuck', 'gave', 'you', 'your', 'start', 'boy', 'Or', 'you', 'wan', 'na', 'be', 'a', 'muthafuckin', 'funny', 'guy', 'Do', \"n't\", 'make', 'me', 'break', 'your', 'Kevin', 'heart', 'boy', 'Yeah', 'it', \"'s\", 'whatever', 'You', 'know', 'feeling', 'good', 'living', 'better', 'I', 'think', 'maybe', 'I', 'was', 'numb', 'to', 'it', 'last', 'year', 'But', 'you', 'know', 'I', 'feel', 'it', 'now', 'more', 'than', 'ever', 'My', 'city', 'love', 'me', 'like', 'Mac', 'Dre', 'in', 'the', 'Bay', 'Second', 'album', 'I', \"'m\", 'back', 'paving', 'the', 'way', 'The', 'backpackers', 'are', 'back', 'on', 'the', 'bandwagon', 'Like', 'this', 'was', 'my', 'comeback', 'season', 'back', 'back', 'in', 'the', 'day', 'And', 'I', 'met', 'your', 'baby', 'moms', 'last', 'night', 'We', 'took', 'a', 'picture', 'together', 'I', 'hope', 'she', 'frames', 'it', 'And', 'I', 'was', 'drinking', 'at', 'the', 'Palms', 'last', 'night', 'And', 'ended', 'up', 'losing', 'everything', 'that', 'I', 'came', 'with', 'Feel', 'like', 'I', \"'ve\", 'been', 'here', 'before', 'huh', 'I', 'still', 'got', '10', 'years', 'to', 'go', 'huh', 'This', 'is', 'the', 'only', 'sound', 'you', 'should', 'fear', 'These', 'kids', 'wear', 'crowns', 'over', 'here', 'And', 'everything', 'is', 'all', 'right', 'I', 'know', 'I', 'know', 'that', 'you', 'love', 'me', 'baby', 'The', 'time', 'to', 'take', 'you', 'away', 'from', 'me', 'Only', 'over', 'my', 'dead', 'body']\n",
      "\n",
      " [Sentence(\"\":\"How I'm feeling, it doesn't matter, Cause you know I'm okay, Instead, I ask myself \"why do you hurt me?\"), Sentence(\"\", When you know, you know I'm the same, I know, I know that you love me baby, Time to take you away from me Only over my dead body...\"), Sentence(\"I think I killed everybody in the game last year, man Fuck it I was on though And I thought I found the girl of my dreams at a strip club Fuck it I was wrong though Shout out all to all my niggas living tax free Now-a-days it's six figures when they tax me Oh well, I guess you lose some and win some Long as the outcome is income You know I want it all and then some Shout out to Asian girls, let the lights dim sum Shots came, I don't know where they was sent from Probably some bad hoes about to take the hemp from Yeah, you know me well nigga I mean you ain't the only real nigga They got me on these white women like Seal nigga Slave to the pussy but I'm just playing the field nigga Are these people discussing my career again?\"), Sentence(\"Asking if I'll be going platinum in a year again Don't I got the shit the world wanna hear again?\"), Sentence(\"Don't Michael Jordan still got his hoop earing in?\"), Sentence(\"Man all of your flows bore me: paint drying And I don't ever be trippin off of what ain't mine And I be hearing shit you say through the grapevine But jealousy is just love and hate at the same time It's been that way from the beginning I just been playing, I ain't even know that I was winning And this is the only sound you should fear Man, these kids wear crowns over here and everything is alright  I know, I know that you love me baby The time to take you away from me Only over my dead body  You say I'm old news, where who the new star?\"), Sentence(\"Cause if I'm going anyway, it's probably too far Just performed at a Bar Mitzvah over in the states Used half of the money to beat my brother's case Red wine over Fed time And shout out to the niggas that's doing deadtime Shout out to the bitches there when it's bedtime And fuck you to the niggas that think it's their time Yeah, don't make me take your life apart boy You and whoever the fuck gave you your start boy Or you wanna be a muthafuckin funny guy?\"), Sentence(\"Don't make me break your Kevin heart boy Yeah, it's whatever.\"), Sentence(\"You know, feeling good, living better I think maybe I was numb to it last year But you know I feel it now more than ever My city love me like Mac Dre in the Bay Second album, I'm back paving the way The backpackers are back on the bandwagon Like this was my comeback season back, back in the day And I met your baby moms last night We took a picture together - I hope she frames it!\"), Sentence(\"And I was drinking at the Palms last night And ended up losing everything that I came with Feel like I've been here before huh?\"), Sentence(\"I still got 10 years to go huh?\"), Sentence(\"This is the only sound you should fear These kids wear crowns over here And everything is all right  I know, I know that you love me baby The time to take you away from me Only over my dead body\"}'\")]\n",
      "\n",
      " ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'negative', 'positive', 'sadness', 'surprise', 'trust', 'anger', 'fear', 'negative', 'sadness', 'joy', 'positive', 'joy', 'positive', 'anticipation', 'joy', 'positive', 'trust', 'negative', 'sadness', 'negative', 'negative', 'sadness', 'negative', 'sadness', 'surprise', 'anger', 'disgust', 'fear', 'negative', 'sadness', 'surprise', 'positive', 'anticipation', 'joy', 'negative', 'positive', 'sadness', 'trust', 'anger', 'disgust', 'fear', 'negative', 'sadness', 'positive', 'trust', 'anticipation', 'joy', 'positive', 'trust', 'anticipation', 'positive', 'anger', 'disgust', 'negative', 'fear', 'negative', 'sadness', 'negative', 'fear', 'negative', 'anger', 'disgust', 'negative', 'anger', 'disgust', 'fear', 'negative', 'sadness', 'joy', 'positive', 'anger', 'disgust', 'fear', 'negative', 'sadness', 'anticipation', 'anticipation', 'disgust', 'joy', 'positive', 'sadness', 'surprise', 'trust', 'anger', 'fear', 'negative', 'negative', 'trust', 'joy', 'positive', 'joy', 'positive', 'anticipation', 'anticipation', 'joy', 'positive', 'trust', 'anger', 'anticipation', 'joy', 'positive', 'surprise', 'trust', 'positive', 'trust', 'fear', 'negative', 'sadness', 'anticipation', 'anger', 'surprise', 'anticipation', 'disgust', 'negative', 'anticipation', 'disgust', 'negative', 'fear', 'negative', 'sadness', 'surprise', 'disgust', 'negative', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'negative', 'positive', 'sadness', 'surprise', 'trust', 'anticipation', 'joy', 'positive', 'surprise', 'trust', 'negative', 'joy', 'positive', 'joy', 'positive', 'anticipation', 'joy', 'positive', 'surprise', 'trust', 'negative', 'anger', 'negative', 'sadness', 'anger', 'fear', 'negative', 'negative', 'trust', 'joy', 'positive', 'joy', 'positive', 'anticipation']\n",
      "\n",
      " {'feeling': ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'negative', 'positive', 'sadness', 'surprise', 'trust'], 'hurt': ['anger', 'fear', 'negative', 'sadness'], 'love': ['joy', 'positive'], 'baby': ['joy', 'positive'], 'thought': ['anticipation'], 'found': ['joy', 'positive', 'trust'], 'strip': ['negative', 'sadness'], 'wrong': ['negative'], 'tax': ['negative', 'sadness'], 'guess': ['surprise'], 'lose': ['anger', 'disgust', 'fear', 'negative', 'sadness', 'surprise'], 'outcome': ['positive'], 'income': ['anticipation', 'joy', 'negative', 'positive', 'sadness', 'trust'], 'bad': ['anger', 'disgust', 'fear', 'negative', 'sadness'], 'real': ['positive', 'trust'], 'white': ['anticipation', 'joy', 'positive', 'trust'], 'career': ['anticipation', 'positive'], 'shit': ['anger', 'disgust', 'negative'], 'wan': ['fear', 'negative', 'sadness'], 'bore': ['negative'], 'hearing': ['fear', 'negative'], 'jealousy': ['anger', 'disgust', 'fear', 'negative', 'sadness'], 'hate': ['anger', 'disgust', 'fear', 'negative', 'sadness'], 'time': ['anticipation'], 'winning': ['anticipation', 'disgust', 'joy', 'positive', 'sadness', 'surprise', 'trust'], 'fear': ['anger', 'fear', 'negative'], 'wear': ['negative', 'trust'], 'star': ['anticipation', 'joy', 'positive', 'trust'], 'money': ['anger', 'anticipation', 'joy', 'positive', 'surprise', 'trust'], 'brother': ['positive', 'trust'], 'case': ['fear', 'negative', 'sadness'], 'shout': ['anger', 'surprise'], 'boy': ['disgust', 'negative'], 'start': ['anticipation'], 'break': ['surprise'], 'good': ['anticipation', 'joy', 'positive', 'surprise', 'trust'], 'numb': ['negative'], 'hope': ['anticipation', 'joy', 'positive', 'surprise', 'trust'], 'drinking': ['negative'], 'losing': ['anger', 'negative', 'sadness']}\n",
      "\n",
      " {'anger': 14, 'anticipation': 17, 'disgust': 12, 'fear': 13, 'joy': 19, 'negative': 29, 'positive': 23, 'sadness': 16, 'surprise': 10, 'trust': 14}\n",
      "\n",
      " [('negative', 0.17365269461077845)]\n",
      "\n",
      " {'fear': 0.07784431137724551, 'anger': 0.08383233532934131, 'anticip': 0.0, 'trust': 0.08383233532934131, 'surprise': 0.059880239520958084, 'positive': 0.1377245508982036, 'negative': 0.17365269461077845, 'sadness': 0.09580838323353294, 'disgust': 0.0718562874251497, 'joy': 0.11377245508982035, 'anticipation': 0.10179640718562874}\n"
     ]
    }
   ],
   "source": [
    "print('\\n', emotion.words)\n",
    "print('\\n', emotion.sentences)\n",
    "print('\\n', emotion.affect_list)\n",
    "print('\\n', emotion.affect_dict)\n",
    "print('\\n', emotion.raw_emotion_scores)\n",
    "print('\\n', emotion.top_emotions)\n",
    "print('\\n', emotion.affect_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9607.61s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.47.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2023.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.10/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at arpanghoshal/EmoRoBERTa.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "testing = pipeline('sentiment-analysis', model='arpanghoshal/EmoRoBERTa')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\":\"Luke White on the beat!, You ever seen a nigga hung with a gold chain?, I\\'d rather sing about the same things that we claim, Such is bashful, but niggas like the task force, Mobbin\\' on the streets and robbin\\' stores in ski masks, bruh Niggas ask for peace in a riot and bring violence \\'Cause it\\'s a game of cat and mouse and you gon\\' bleed silent What\\'s the justice in sayin\\', \"Fuck it,\" and grab the pump? Then kill a woman with many children makes you a chump Look at all the stores you wreckin\\', nigga I reckon Think about the people who own it for about a second I know you got your problems, but brother, they got theirs This is not a game, quit violence and grow a pair But yo, you\\'d rather hear me say, \"Fuck the black prejudice\" Let\\'s murder different races, grow hatred, and form irrelevant Views\" and etcetera, knives thrown Damage \\'em, lives blown, oblivion hole cold, oblivious I won\\'t dare say that you should stop the fuckin\\' ignorance Murder ops, killin\\' shit, I\\'d enjoy the thrill of it Bathe in blood of officers, different corpses, offin\\' \\'em Auction \\'em, don\\'t you bark at \\'em Murder \\'em, never heard of \\'em I could preach the peace but say, \"Fuck it,\" and preach the murder \\'Cause this ain\\'t fuckin\\' life that we livin\\' Go ahead and grab the extension Grab another one: uncle, cousin, brother, son Glory to all the chosen ones that will rid you of the innocence But in a sense, innocent will soon behold the ignorance Blasphemous, killin\\' our own, murderin\\' blackxe2x80x94  We see, I see, death before the children White guys and white girls hanging from the buildings We hate niggers! We hate Jews! We hate faggots! And we hate spics! Hooray! We don\\'t have to have a reason to hate them Just because they breathe we hate their filthy bums! You people need to get off your ass and wake up This is America, the niggers are taking it over and the Jews Make a stand, join the klan White power! White power! White power! And I hate Jews! I hate them because they exist! I hate them because they breathe! I hate them because they\\'re scum! The goddamn niggers are the scum of the earth! White power!\"}\\''"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSong(\"XXXTENTACION\", \"RIOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "mRoom = getSong(\"XXXTENTACION\", \"RIOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = testing(mRoom)\n",
    "emotion_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'anger', 'score': 0.7901594638824463}]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Using DataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "10606.02s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.6-py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kagglehub) (2.31.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kagglehub) (21.3)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kagglehub) (4.65.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from packaging->kagglehub) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->kagglehub) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->kagglehub) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->kagglehub) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->kagglehub) (2024.8.30)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.6\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.10/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"imsparsh/multimodal-mirex-emotion-dataset\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "19095.44s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement itertools (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for itertools\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.10/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Passionate'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def get_nth_line(n):\n",
    "    with open('1/dataset/categories.txt', \"r\") as file:\n",
    "        line = next(islice(file, n - 1, n), None)  # Get the (n-1)th index\n",
    "        return line.strip() if line else None\n",
    "\n",
    "get_nth_line(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_dict = {\n",
    "    \"Rollicking\": \"Energetic and Bold\",\n",
    "    \"Confident\": \"Energetic and Bold\",\n",
    "    \"Rousing\": \"Energetic and Bold\",\n",
    "    \"Fiery\": \"Energetic and Bold\",\n",
    "    \"Boisterous\": \"Energetic and Bold\",\n",
    "    \"Agressive\": \"Energetic and Bold\",\n",
    "    \"Poignant\": \"Reflective and Somber\",\n",
    "    \"Wistful\": \"Reflective and Somber\",\n",
    "    \"Bittersweet\": \"Reflective and Somber\",\n",
    "    \"Brooding\": \"Reflective and Somber\",\n",
    "    \"Autumnal\": \"Reflective and Somber\",\n",
    "    \"Tense - Anxious\": \"Reflective and Somber\",\n",
    "    \"Fun\": \"Humorous and Lighthearted\",\n",
    "    \"Wry\": \"Humorous and Lighthearted\",\n",
    "    \"Witty\": \"Humorous and Lighthearted\",\n",
    "    \"whimsical\": \"Humorous and Lighthearted\",\n",
    "    \"Silly\": \"Humorous and Lighthearted\",\n",
    "    \"Cheerful\": \"Humorous and Lighthearted\",\n",
    "    \"Passionate\": \"Romantic and Sentimental\",\n",
    "    \"Sweet\": \"Romantic and Sentimental\",\n",
    "    \"Amiable-good natured\": \"Romantic and Sentimental\",\n",
    "    \"Campy\": \"Romantic and Sentimental\",\n",
    "    \"Humorous\": \"Romantic and Sentimental\",\n",
    "    \"Visceral\": \"Romantic and Sentimental\",\n",
    "    \"Volatile\": \"Complex and Dramatic\",\n",
    "    \"Literate\": \"Complex and Dramatic\",\n",
    "    \"Rowdy\": \"Complex and Dramatic\",\n",
    "    \"Intense\": \"Complex and Dramatic\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>289.txt</td>\n",
       "      <td>It's happy hour again\\nI think I might be happ...</td>\n",
       "      <td>Energetic and Bold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>504.txt</td>\n",
       "      <td>Oh, breaking up is so \\nvery hard to do\\n\\nIf ...</td>\n",
       "      <td>Reflective and Somber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262.txt</td>\n",
       "      <td>Nibblin' on sponge cake,\\nwatchin' the sun bak...</td>\n",
       "      <td>Humorous and Lighthearted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276.txt</td>\n",
       "      <td>Last night I sat my baby right down \\nAnd said...</td>\n",
       "      <td>Energetic and Bold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510.txt</td>\n",
       "      <td>We can't play this game anymore, but\\nCan we s...</td>\n",
       "      <td>Reflective and Somber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>253.txt</td>\n",
       "      <td>Just let me hear some of that rock and roll mu...</td>\n",
       "      <td>Humorous and Lighthearted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>247.txt</td>\n",
       "      <td>Dearly beloved\\nWe are gathered here today to ...</td>\n",
       "      <td>Humorous and Lighthearted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>521.txt</td>\n",
       "      <td>They say that these are not the best of times\\...</td>\n",
       "      <td>Reflective and Somber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>290.txt</td>\n",
       "      <td>Well, she was a-walkin down the street, \\nlook...</td>\n",
       "      <td>Energetic and Bold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>284.txt</td>\n",
       "      <td>Hey porter! Hey porter!\\nWould you tell me the...</td>\n",
       "      <td>Energetic and Bold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>764 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename                                            content  \\\n",
       "0    289.txt  It's happy hour again\\nI think I might be happ...   \n",
       "1    504.txt  Oh, breaking up is so \\nvery hard to do\\n\\nIf ...   \n",
       "2    262.txt  Nibblin' on sponge cake,\\nwatchin' the sun bak...   \n",
       "3    276.txt  Last night I sat my baby right down \\nAnd said...   \n",
       "4    510.txt  We can't play this game anymore, but\\nCan we s...   \n",
       "..       ...                                                ...   \n",
       "759  253.txt  Just let me hear some of that rock and roll mu...   \n",
       "760  247.txt  Dearly beloved\\nWe are gathered here today to ...   \n",
       "761  521.txt  They say that these are not the best of times\\...   \n",
       "762  290.txt  Well, she was a-walkin down the street, \\nlook...   \n",
       "763  284.txt  Hey porter! Hey porter!\\nWould you tell me the...   \n",
       "\n",
       "                      category  \n",
       "0           Energetic and Bold  \n",
       "1        Reflective and Somber  \n",
       "2    Humorous and Lighthearted  \n",
       "3           Energetic and Bold  \n",
       "4        Reflective and Somber  \n",
       "..                         ...  \n",
       "759  Humorous and Lighthearted  \n",
       "760  Humorous and Lighthearted  \n",
       "761      Reflective and Somber  \n",
       "762         Energetic and Bold  \n",
       "763         Energetic and Bold  \n",
       "\n",
       "[764 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the directory where your text files are located\n",
    "from itertools import islice\n",
    "import os\n",
    "data_list = []\n",
    "categories = []\n",
    "directory = '1/dataset/Lyrics'\n",
    "\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "\n",
    "\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Read the text file and append its content to the data_list\n",
    "        with open(file_path, 'r') as file:\n",
    "\n",
    "            temp = categories_dict.get(get_nth_line(int(filename.replace(\".txt\", \"\"))))\n",
    "            if (temp == None):\n",
    "                print(\"filename is: \" + filename + \" and the category is: \" + get_nth_line(int(filename.replace(\".txt\", \"\")))) \n",
    "\n",
    "\n",
    "            content = file.read()\n",
    "            if (temp not in categories):\n",
    "                categories.append(temp)\n",
    "\n",
    "            data_list.append({'filename': filename, 'content': content, 'category': temp})\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df = pd.DataFrame(data_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reflective and Somber        187\n",
      "Humorous and Lighthearted    173\n",
      "Romantic and Sentimental     165\n",
      "Energetic and Bold           146\n",
      "Complex and Dramatic          93\n",
      "Name: category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Energetic and Bold',\n",
       " 'Reflective and Somber',\n",
       " 'Humorous and Lighthearted',\n",
       " 'Romantic and Sentimental',\n",
       " 'Complex and Dramatic']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts texts to numbers based on how many times it appears in a document\n",
    "\n",
    "#Result is a matrix where rows = lyrics, Columns = frequency of words\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['content'], df['category'], test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "#Essentially, we are converting our text in to numbers that computer can understand using countvectorizer\n",
    "\n",
    "#         the    house   is   big  dog  barked\n",
    "#text1     1       1      1    1     0   0 \n",
    "#text2     1       0      0     0    1   1\n",
    "# \n",
    "# Just creating a very very basic matrix that essentially \"tokenizes\" every word\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687, 8987)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some words not relevant so we can do a tf which doesn't account for common \n",
    "#Might look something like this\n",
    "#         Night  House  Floor\n",
    "#song1     0.5    0.1    0\n",
    "#song2     0.23   0.4    0.5\n",
    "\n",
    "\n",
    "#Tf measures how many times a word appears in a single document\n",
    "#IDF measures how often a word appears in all your documents and inverses that bc a word like \n",
    "#\"The\" is not that important\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a Naive Bayes classifier in this example\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = RandomForestClassifier(n_estimators=100).fit(X_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# clf = LogisticRegression(max_iter=200)\n",
    "# clf.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming l1 to a matrix\n",
    "X_new_counts = count_vect.transform(X_test)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_new_tfidf)\n",
    "# for doc, category in zip(X_test, predicted):\n",
    "#     print('%r => %s' % (doc, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf',  MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33766233766233766"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3116883116883117"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "       Energetic and Bold       0.25      0.11      0.15         9\n",
      "    Reflective and Somber       0.32      0.40      0.35        15\n",
      "Humorous and Lighthearted       0.23      0.38      0.29        13\n",
      " Romantic and Sentimental       0.45      0.50      0.48        20\n",
      "     Complex and Dramatic       0.20      0.10      0.13        20\n",
      "\n",
      "                 accuracy                           0.31        77\n",
      "                macro avg       0.29      0.30      0.28        77\n",
      "             weighted avg       0.30      0.31      0.29        77\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  3,  3,  1],\n",
       "       [ 1,  6,  3,  2,  3],\n",
       "       [ 0,  5,  5,  3,  0],\n",
       "       [ 1,  3,  2, 10,  4],\n",
       "       [ 1,  4,  9,  4,  2]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "metrics.confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-2, 1e-3),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Romantic and Sentimental'], dtype='object')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [109]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgs_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGod is love\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:984\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    981\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_values(key)\n\u001b[0;32m--> 984\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:1024\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[key]\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m# handle the dup indexing case GH#4246\u001b[39;00m\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1324\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1325\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1327\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Romantic and Sentimental'], dtype='object')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "X_train[gs_clf.predict(['God is love'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35801332910187245"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: False\n",
      "vect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.08706689, 0.24987378, 0.06073666, 0.22472849, 0.06901584,\n",
       "        0.22249999, 0.06465778, 0.16711984]),\n",
       " 'std_fit_time': array([0.0094298 , 0.01811665, 0.01391501, 0.01545404, 0.00650456,\n",
       "        0.05724743, 0.00912212, 0.01645299]),\n",
       " 'mean_score_time': array([0.01392403, 0.03896537, 0.01815786, 0.02917209, 0.01494055,\n",
       "        0.03396459, 0.01181016, 0.01974797]),\n",
       " 'std_score_time': array([0.0047786 , 0.01179314, 0.00677305, 0.0068857 , 0.00164388,\n",
       "        0.00761686, 0.0031856 , 0.00131771]),\n",
       " 'param_clf__alpha': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001, 0.001],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_tfidf__use_idf': masked_array(data=[True, True, False, False, True, True, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_vect__ngram_range': masked_array(data=[(1, 1), (1, 2), (1, 1), (1, 2), (1, 1), (1, 2), (1, 1),\n",
       "                    (1, 2)],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'clf__alpha': 0.01,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  {'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)},\n",
       "  {'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)},\n",
       "  {'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)},\n",
       "  {'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)},\n",
       "  {'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)},\n",
       "  {'clf__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)},\n",
       "  {'clf__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}],\n",
       " 'split0_test_score': array([0.29710145, 0.34057971, 0.34782609, 0.33333333, 0.30434783,\n",
       "        0.28985507, 0.33333333, 0.36956522]),\n",
       " 'split1_test_score': array([0.39855072, 0.38405797, 0.42028986, 0.39130435, 0.37681159,\n",
       "        0.36231884, 0.4057971 , 0.39130435]),\n",
       " 'split2_test_score': array([0.35766423, 0.40145985, 0.35036496, 0.37956204, 0.2919708 ,\n",
       "        0.37226277, 0.35766423, 0.40145985]),\n",
       " 'split3_test_score': array([0.27737226, 0.29927007, 0.37226277, 0.3649635 , 0.27007299,\n",
       "        0.27737226, 0.33576642, 0.29927007]),\n",
       " 'split4_test_score': array([0.29927007, 0.27737226, 0.27737226, 0.28467153, 0.27007299,\n",
       "        0.30656934, 0.31386861, 0.32846715]),\n",
       " 'mean_test_score': array([0.32599175, 0.34054797, 0.35362319, 0.35076695, 0.30265524,\n",
       "        0.32167566, 0.34928594, 0.35801333]),\n",
       " 'std_test_score': array([0.04512317, 0.04753612, 0.04615258, 0.03833149, 0.03934309,\n",
       "        0.03850835, 0.03148129, 0.03860851]),\n",
       " 'rank_test_score': array([6, 5, 2, 3, 8, 7, 4, 1], dtype=int32)}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.cv_results_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
